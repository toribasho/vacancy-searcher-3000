{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "осталось 18 типов вакансий\n",
      "\n",
      "Всего 122 новых вакансий\n"
     ]
    }
   ],
   "source": [
    "# ищем только вакансии где есть такие слова (поиск от hh, оэтому похожие слова тоже попадают)\n",
    "vacancies_to_look_in_name = ['Аналитик','Analyst','Data Scientist',\n",
    "                            'Data Science','ML','LLM',\n",
    "                            'Machine Learning','прогнозирование','анализ']\n",
    "\n",
    "# указываем в каких странах мы заинтересованы только для удаленки, и в каких - согласны на любой формат\n",
    "countries_and_schedule = {'remote':[113, 5, 16], 'not_given':[40, 97, 9, 48, 1001, 28]}\n",
    "# 'area': 113 Россия; 'area': 40 Казахстан; 5 и 16 - Украина и Беларусь; остальное - разные другие страны\n",
    "\n",
    "# те страны которые только для удаленки - берем во-первых вакансии где указан удаленный режим, \n",
    "# во-вторых смотрим ВСЕ режимы, и отбираем вакансии где в описании есть следующие слова:\n",
    "remote_words = ['удалён','удален','за пределами рф','дистанцион','из дома','remote',\n",
    "                'relocation','релокаци','из другой страны','из любой точки мира','online']\n",
    "\n",
    "# если эти слова есть в названии вакансии, то эти вакансии автоматически исключаем из просмотра, чтобы не тратить время\n",
    "exclude_words_IN_NAME = ['1c', '1с', 'системн', 'финансов', 'senior', 'lead', 'старший', 'ведущий',\n",
    "                         'эксперт', 'автор', 'developer', 'лаборант', 'руководитель', 'менеджер',\n",
    "                         'бизнес', 'экономист', 'химик', 'начальник', 'главный', 'медсестра',\n",
    "                         'спикер', 'архитектор', 'бухгалтер', 'директор', 'business', 'научный', \n",
    "                         'линии поддержки', 'ozon', 'wildberries', 'маркетплейс', 'system', 'писатель',\n",
    "                         'безопасность','куратор','golang','оператор','financial','информационной безопасности']\n",
    "\n",
    "# число календарных дней за которое подтягиваем историю загрузки вакансий, брала с запасом, чтобы ничего не упустить, \n",
    "# но большинство вакансий повторяются, так что на увеличении времени это не сильно сказывается (начиная со второго прогона кода)\n",
    "days_to_look = 2\n",
    "\n",
    "# т.к. я искала 9 вакансий по 9 разным странам, плюс страны для удаленки прогоняются дважды, \n",
    "# то у меня выходило 108 запросов, и при прохождении каждых 10 код выдает print, чтобы понимать сколько осталось\n",
    "print_every_N_steps = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "vacancies_to_look_in_name = ['NAME:'+x for x in vacancies_to_look_in_name]\n",
    "n_vacancies = len(vacancies_to_look_in_name)\n",
    "all_countries = sum(list(list(countries_and_schedule.values())+[countries_and_schedule['remote']]), [])\n",
    "n_countries = len(all_countries)\n",
    "countries_iteration = sum([[x]*n_vacancies for x in all_countries],[])\n",
    "n_remote = len(countries_and_schedule['remote'])\n",
    "all_schedules = ['remote']*n_remote*n_vacancies+[None]*\\\n",
    "                (n_countries-n_remote)*n_vacancies\n",
    "remote_words_there = 0\n",
    "\n",
    "\n",
    "def getPage(page = 0, vacancy_type = 0):\n",
    "\n",
    "    all_params = {\n",
    "        'text': vacancies_to_look_in_name*n_countries, # Текст поиска\n",
    "        'schedule': all_schedules,\n",
    "        'period': [days_to_look]*n_vacancies*n_countries, # 1 - за сутки; 3 - за 3 дня, 7 - за неделю\n",
    "        'area': countries_iteration, \n",
    "        'page': [page]*n_vacancies*n_countries, # Индекс страницы поиска на HH\n",
    "        'per_page': [100]*n_vacancies*n_countries # Кол-во вакансий на 1 странице\n",
    "    }\n",
    "\n",
    "    params = {x:all_params[x][vacancy_type] for x in all_params.keys()}\n",
    "\n",
    "    req = requests.get('https://api.hh.ru/vacancies', params) # Посылаем запрос к API\n",
    "    data = req.content.decode() # Декодируем его ответ, чтобы Кириллица отображалась корректно\n",
    "    req.close()\n",
    "    return data\n",
    "\n",
    "all_v=[]\n",
    "try:\n",
    "    all_vc = pd.read_csv('all_vacancies.csv')\n",
    "except:\n",
    "    all_vc = pd.DataFrame(columns=['vacancy_url'])\n",
    "new_df = pd.DataFrame(columns=['name','exp','url','descr','sch','loc'])\n",
    "try:\n",
    "    for dir in ['docs/vacancies', 'docs/pagination']:\n",
    "        for f in os.listdir(dir):\n",
    "            os.remove(os.path.join(dir, f))\n",
    "except:\n",
    "    pass\n",
    "# чтобы видеть целиком описание вакансии\n",
    "pd.set_option('display.max_colwidth', 10000)\n",
    "\n",
    "def pretty_print(df):\n",
    "    return display( HTML( df.style.set_properties(**{'text-align': 'left'}).to_html().replace(\"\\\\n  <strong>\",\"<br> <strong>\").replace(\"<strong>\",\"<br> <strong>\").replace(\"\\\\n\",\"<br> ⏺\") ) )\n",
    "\n",
    "\n",
    "\n",
    "# проходимся по всем типам вакансий\n",
    "for i in range(n_vacancies*n_countries):\n",
    "    # проходимся по всем страницам поиска\n",
    "    for page in range(0, 100):\n",
    "        # Преобразуем текст ответа запроса в справочник Python\n",
    "        jsObj = json.loads(getPage(page, i))\n",
    "        \n",
    "        # Сохраняем файлы в папку {путь до текущего документа со скриптом}\\docs\\pagination\n",
    "        # Определяем количество файлов в папке для сохранения документа с ответом запроса\n",
    "        # Полученное значение используем для формирования имени документа\n",
    "        nextFileName = './docs/pagination/{}.json'.format(len(os.listdir('./docs/pagination')))\n",
    "        \n",
    "        # Создаем новый документ, записываем в него ответ запроса, после закрываем\n",
    "        f = open(nextFileName, mode='w', encoding='utf8')\n",
    "        f.write(json.dumps(jsObj, ensure_ascii=False))\n",
    "        f.close()\n",
    "        \n",
    "        # Проверка на последнюю страницу, если вакансий меньше 10000\n",
    "        if (jsObj['pages'] - page) <= 1:\n",
    "            break\n",
    "        \n",
    "        # Необязательная задержка, но чтобы не нагружать сервисы hh, оставим\n",
    "        time.sleep(0.25)\n",
    "\n",
    "    # проходимся по всем вакансиям\n",
    "    for fl in os.listdir('./docs/pagination'):\n",
    "        \n",
    "        # Открываем файл, читаем его содержимое, закрываем файл\n",
    "        f = open('./docs/pagination/{}'.format(fl), encoding='utf8')\n",
    "        jsonText = f.read()\n",
    "        f.close()\n",
    "        \n",
    "        # Преобразуем полученный текст в объект справочника\n",
    "        jsonObj = json.loads(jsonText)\n",
    "        \n",
    "        # Получаем и проходимся по непосредственно списку вакансий\n",
    "        for v in jsonObj['items']:\n",
    "            if (v['url'] not in list(all_vc['vacancy_url'])) and (v['url'] not in all_v):\n",
    "            \n",
    "                # Обращаемся к API и получаем детальную информацию по конкретной вакансии\n",
    "                all_v.append(v['url'])\n",
    "                req = requests.get(v['url'])\n",
    "                data = req.content.decode()\n",
    "                req.close()\n",
    "                \n",
    "                # Создаем файл в формате json с идентификатором вакансии в качестве названия\n",
    "                # Записываем в него ответ запроса и закрываем файл\n",
    "                fileName = './docs/vacancies/{}.json'.format(v['id'])\n",
    "                f = open(fileName, mode='w', encoding='utf8')\n",
    "                f.write(data)\n",
    "                f.close()\n",
    "                \n",
    "                time.sleep(0.25)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # добавляем в датафрейм\n",
    "    list_files = os.listdir('./docs/vacancies')\n",
    "    for vacancy in list_files:\n",
    "        f = open('./docs/vacancies/{}'.format(vacancy), encoding='utf8')\n",
    "        jsonText = f.read()\n",
    "        f.close()\n",
    "        jsonObj = json.loads(jsonText)\n",
    "\n",
    "        if i >= n_vacancies*n_countries:\n",
    "            remote_words_there=1 if any(word in jsonObj['description'].lower() for word in remote_words) else 0\n",
    "\n",
    "        if remote_words_there or (i < n_vacancies*(n_countries-n_remote)):\n",
    "            if not any(word in jsonObj['name'].lower() for word in exclude_words_IN_NAME):\n",
    "                stri = jsonObj['description']\n",
    "                # stri = stri.replace('<strong>','\\033[1m')\n",
    "                # stri = stri.replace('</strong>','\\033[0m')\n",
    "                stri = stri.replace('</li> <li>','\\\\n')\n",
    "                stri = stri.replace('<ul> <li>','\\\\n')\n",
    "                stri = stri.replace('</li>','\\\\n')\n",
    "                stri = stri.replace('</ul>','')\n",
    "\n",
    "                new_df.loc[len(new_df)] = [jsonObj['name'], \n",
    "                                    jsonObj['experience']['id'],\n",
    "                                    jsonObj['alternate_url'], \n",
    "                                    stri,\n",
    "                                    jsonObj['schedule']['id'],\n",
    "                                    jsonObj['area']['name']]\n",
    "\n",
    "    # удаляем файлы\n",
    "    for dir in ['docs/vacancies', 'docs/pagination']:\n",
    "        for f in os.listdir(dir):\n",
    "            os.remove(os.path.join(dir, f))\n",
    "\n",
    "    # отслеживаем работу\n",
    "    if (i%print_every_N_steps==0)&(len(str(n_vacancies*n_countries - i))>1):\n",
    "        if n_vacancies*n_countries - i >= 100:\n",
    "            print('осталось '+str(n_vacancies*n_countries - i)+' типов', end='')\n",
    "        else:\n",
    "            print('осталось '+str(n_vacancies*n_countries - i)+' типов вакансий', end='')\n",
    "        print('\\r', end='')\n",
    "\n",
    "print('\\n\\nВсего '+str(len(new_df))+' новых вакансий')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если мало (меньше 10)\n",
    "pretty_print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS без опыта\n",
    "pretty_print(new_df[(new_df['name'].str.contains(r'scientist|ml|llm|science|learning', case=False, regex=True))&\\\n",
    "                    (new_df['exp']=='noExperience')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS с любым опытом\n",
    "pretty_print(new_df[(new_df['name'].str.contains(r'scientist|ml|llm|science|learning', case=False, regex=True))&\\\n",
    "                    ~(new_df['exp']=='noExperience')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# аналитик на удаленке + английский\n",
    "pretty_print(new_df[(new_df['name'].str.contains(r'analyst|аналитик|прогнозирован', case=False, regex=True))&\\\n",
    "                    (new_df['sch']=='remote')&\\\n",
    "                    (new_df['descr'].str.contains(r'english|английск', case=False, regex=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_606e2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_606e2_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_606e2_level0_col1\" class=\"col_heading level0 col1\" >exp</th>\n",
       "      <th id=\"T_606e2_level0_col2\" class=\"col_heading level0 col2\" >url</th>\n",
       "      <th id=\"T_606e2_level0_col3\" class=\"col_heading level0 col3\" >descr</th>\n",
       "      <th id=\"T_606e2_level0_col4\" class=\"col_heading level0 col4\" >sch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# аналитик на удаленке без английского\n",
    "pretty_print(new_df[(new_df['name'].str.contains(r'analyst|аналитик|прогнозирован', case=False, regex=True))&\\\n",
    "                    (new_df['sch']=='remote')&\\\n",
    "                    ~(new_df['descr'].str.contains(r'english|английск', case=False, regex=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7895e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7895e_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_7895e_level0_col1\" class=\"col_heading level0 col1\" >exp</th>\n",
       "      <th id=\"T_7895e_level0_col2\" class=\"col_heading level0 col2\" >url</th>\n",
       "      <th id=\"T_7895e_level0_col3\" class=\"col_heading level0 col3\" >descr</th>\n",
       "      <th id=\"T_7895e_level0_col4\" class=\"col_heading level0 col4\" >sch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# всё оставшееся (не аналитик на удаленке и не ds)\n",
    "pretty_print(new_df[~((new_df['name'].str.contains(r'analyst|аналитик|прогнозирован', case=False, regex=True))&(new_df['sch']=='remote'))&\\\n",
    "                    ~(new_df['name'].str.contains(r'scientist|ml|llm|science|learning', case=False, regex=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем новые вакансии в просмотренное:\n",
    "new_v = pd.concat([all_vc, pd.DataFrame(all_v, columns=['vacancy_url'])])\n",
    "new_v.to_csv('all_vacancies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "env_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
